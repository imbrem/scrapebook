{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, Optional, Iterable, Set, Union, Tuple\n",
    "from jsonpath_ng import parse as jsonpath_parse\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "import json, os, hashlib, re\n",
    "\n",
    "_HEX_RE = re.compile(r'^[0-9a-fA-F]*$')\n",
    "\n",
    "def hex_to_bytes(h: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Convert a hex string to raw bytes.\n",
    "\n",
    "    Accepts optional '0x' prefix and common separators (space, underscore,\n",
    "    hyphen, colon). Raises TypeError for non-str inputs and ValueError for\n",
    "    invalid hex or odd length after cleaning.\n",
    "    \"\"\"\n",
    "    if not isinstance(h, str):\n",
    "        raise TypeError(\"hex_to_bytes() expects a str\")\n",
    "\n",
    "    s = h.strip()\n",
    "    if s.startswith((\"0x\", \"0X\")):\n",
    "        s = s[2:]\n",
    "\n",
    "    # Remove common separators\n",
    "    for sep in (\" \", \"_\", \"-\", \":\"):\n",
    "        s = s.replace(sep, \"\")\n",
    "\n",
    "    if len(s) % 2 != 0:\n",
    "        raise ValueError(f\"hex string has odd length ({len(s)}): {h!r}\")\n",
    "\n",
    "    if not _HEX_RE.fullmatch(s):\n",
    "        raise ValueError(f\"invalid hex string: {h!r}\")\n",
    "\n",
    "    return bytes.fromhex(s)\n",
    "\n",
    "def sha256_hex(data: bytes) -> str:\n",
    "    \"\"\"Get the hex digest of the SHA-256 hash of the given data\"\"\"\n",
    "    return hashlib.sha256(data).hexdigest()\n",
    "\n",
    "def path_for_key(key: str) -> str:\n",
    "    \"\"\"Get a JSONPath for a given key using bracket notation.\"\"\"\n",
    "    safe = key.replace('\"', r'\\\"')\n",
    "    return f'$[\"{safe}\"]'\n",
    "\n",
    "def extend_path(base: str, key_or_index: Union[str, int]) -> str:\n",
    "    \"\"\"Append a segment to a JSONPath using bracket notation.\"\"\"\n",
    "    if isinstance(key_or_index, str):\n",
    "        seg = path_for_key(key_or_index)[1:]  # '[\"key\"]'\n",
    "        return f\"{base}{seg}\"\n",
    "    if isinstance(key_or_index, int):\n",
    "        return f\"{base}[{key_or_index}]\"\n",
    "    raise TypeError(\"Path extension must be str (field) or int (index).\")\n",
    "\n",
    "def hash_json(data: Any) -> bytes:\n",
    "    \"\"\"Compute a SHA-256 hash of JSON-serializable data.\"\"\"\n",
    "    j = json.dumps(data, separators=(',', ':'), sort_keys=True)\n",
    "    return hashlib.sha256(j.encode('utf-8')).digest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class OperationHeader:\n",
    "    \"\"\"Metadata about an operation.\"\"\"\n",
    "    kind: str # e.g. 'obs' or 'trans' \n",
    "    task: str # e.g. 'fetch_http', 'parse_article'\n",
    "    tool: str # e.g. 'requests', 'my_scraper_1'\n",
    "    output_type: str # e.g. 'http_response', 'article'\n",
    "    event_uuid: Optional[bytes] # e.g. '550e8400-e29b-41d4-a716-446655440000'\n",
    "    timestamp: Optional[str] # e.g. '2024-01-01T12:00:00Z'\n",
    "    meta: Any # Arbitrary JSON metadata\n",
    "\n",
    "    def sha256(self) -> bytes:\n",
    "        \"\"\"\n",
    "        Deterministic SHA-256 over all fields as plain data.\n",
    "        Uses a canonical JSON *list* to preserve field order.\n",
    "        \"\"\"\n",
    "        return hash_json([\n",
    "            self.kind, self.task, self.tool, self.output_type, \n",
    "            None if self.event_uuid is None else self.event_uuid.hex(), \n",
    "            self.timestamp, self.meta\n",
    "        ])\n",
    "    \n",
    "    def op_id(self, inputs, outputs) -> bytes:\n",
    "        \"\"\"\n",
    "        Get the operation ID for this header combined with given inputs and outputs.\n",
    "        \"\"\"\n",
    "        return hash_json([self.sha256().hex(), inputs, outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# -------- JSON leaf tags --------\n",
    "OP_TAG  = \"$op\"          # {\"$op\": {\"id\": \"<hex>\", \"path\": \"$.a.b[0]\"}}\n",
    "ART_TAG = \"$artifact\"    # {\"$artifact\": \"<sha256-hex>\"}\n",
    "\n",
    "OBS_KIND = \"obs\"\n",
    "TRANS_KIND = \"trans\"\n",
    "\n",
    "class Artifact:\n",
    "    \"\"\"Lazy-loaded bytes referenced by SHA-256; caches after first load.\"\"\"\n",
    "    __slots__ = (\"book\", \"sha256\", \"_cache\")\n",
    "\n",
    "    def __init__(self, book: \"Scrapebook\", sha256: bytes):\n",
    "        self.book = book\n",
    "        self.sha256 = sha256\n",
    "        self._cache: Optional[bytes] = None\n",
    "\n",
    "    def bytes(self) -> bytes:\n",
    "        if self._cache is None:\n",
    "            self._cache = self.book.fetch_artifact_bytes_sha256(self.sha256)\n",
    "        return self._cache\n",
    "    \n",
    "    def value(self) -> bytes:\n",
    "        return self.bytes()\n",
    "    \n",
    "    def produced_by(self) -> Set[Operation]:\n",
    "        \"\"\"\n",
    "        Return the set of operations in the book which produce this artifact\n",
    "        \"\"\"\n",
    "        op_ids = self.book.fetch_artifact_produced_by(self.sha256)\n",
    "        return {Operation(self.book, op_id) for op_id in op_ids}\n",
    "    \n",
    "    def consumed_by(self) -> Set[Operation]:\n",
    "        \"\"\"\n",
    "        Return the set of operations in the book which directly consume this artifact\n",
    "        \"\"\"\n",
    "        op_ids = self.book.fetch_artifact_consumed_by(self.sha256)\n",
    "        return {Operation(self.book, op_id) for op_id in op_ids}\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<Artifact {self.sha256.hex()}>\"\n",
    "\n",
    "\n",
    "class Operation:\n",
    "    \"\"\"Lazy header; decoded results/inputs are cached along with their dependency sets.\"\"\"\n",
    "    __slots__ = (\n",
    "        \"book\", \"id\", \"_header\",\n",
    "        \"_results_cache\",\n",
    "        \"_artifacts_produced_cache\",\n",
    "        \"_inputs_cache\",\n",
    "        \"_artifacts_consumed_cache\", \"_deps_cache\",\n",
    "    )\n",
    "\n",
    "    def __init__(self, book: \"Scrapebook\", op_id: bytes):\n",
    "        self.book = book\n",
    "        self.id = op_id\n",
    "        self._header: Optional[OperationHeader] = None\n",
    "\n",
    "        # Results caches\n",
    "        self._results_cache: Optional[Any] = None\n",
    "        self._artifacts_produced_cache: Optional[Set[str]] = None\n",
    "\n",
    "        # Input caches\n",
    "        self._inputs_cache: Optional[Any] = None\n",
    "        self._artifacts_consumed_cache: Optional[Set[Artifact]] = None\n",
    "        self._deps_cache: Optional[Set[Operation]] = None\n",
    "\n",
    "    # --- header (lazy) ---\n",
    "    @property\n",
    "    def header(self) -> OperationHeader:\n",
    "        if self._header is None:\n",
    "            self._header = self.book.fetch_operation_header(self.id)\n",
    "        return self._header\n",
    "\n",
    "    @property\n",
    "    def kind(self) -> str: return self.header.kind\n",
    "    @property\n",
    "    def task(self) -> str: return self.header.task\n",
    "    @property\n",
    "    def tool(self) -> str: return self.header.tool\n",
    "    @property\n",
    "    def output_type(self) -> str: return self.header.output_type\n",
    "    @property\n",
    "    def event_uuid(self) -> Optional[bytes]: return self.header.event_uuid\n",
    "    @property\n",
    "    def timestamp(self) -> Optional[str]: return self.header.timestamp\n",
    "    @property\n",
    "    def meta(self) -> Any: return self.header.meta\n",
    "\n",
    "    # --- result-path handles ---\n",
    "    def __getitem__(self, key: str) -> \"OperationResult\":\n",
    "        return self.at(path_for_key(key))\n",
    "    \n",
    "    def at(self, path: str) -> \"OperationResult\":\n",
    "        \"\"\"Return a handle to the results at the given JSONPath.\"\"\"\n",
    "        return OperationResult(self, path)\n",
    "\n",
    "    # --- results JSON (raw / decoded + deps) ---\n",
    "    def results_json(self) -> Any:\n",
    "        \"\"\"\n",
    "        Get the raw JSON of an operation's results.\n",
    "        \n",
    "        This is _not_ cached; see results() for the cached version\n",
    "        \"\"\"\n",
    "        return self.book.fetch_results_json(self.id)\n",
    "\n",
    "    def _ensure_results(self) -> Any:\n",
    "        if self._results_cache is None:\n",
    "            raw = self.book.fetch_results_json(self.id)\n",
    "            arts = set()\n",
    "            decoded = self.book.decode_json(raw, arts=arts)\n",
    "            self._results_cache = decoded\n",
    "            self._artifacts_produced_cache = arts\n",
    "        return self._results_cache\n",
    "\n",
    "    def results(self) -> Any:\n",
    "        \"\"\"\n",
    "        Get the results of an operation\n",
    "        \"\"\"\n",
    "        return self._ensure_results()\n",
    "\n",
    "    def artifacts_produced(self) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Return the set of artifacts produced by this operation.\n",
    "        \"\"\"\n",
    "        if self._artifacts_produced_cache is None:\n",
    "            self._ensure_results()\n",
    "        return self._artifacts_produced_cache or set()\n",
    "\n",
    "    # --- inputs JSON (raw / decoded + deps) ---\n",
    "    def inputs_json(self) -> Any:\n",
    "        \"\"\"\n",
    "        Get the raw JSON of an operation's inputs.\n",
    "        \n",
    "        This is _not_ cached; see inputs() for the cached version\n",
    "        \"\"\"\n",
    "        return self.book.fetch_inputs_json(self.id)\n",
    "\n",
    "    def _ensure_inputs(self) -> Any:\n",
    "        if self._inputs_cache is None:\n",
    "            raw = self.book.fetch_inputs_json(self.id)\n",
    "            arts = set()\n",
    "            ops = set()\n",
    "            decoded = self.book.decode_json(raw, ops=ops, arts=arts)\n",
    "            self._inputs_cache = decoded\n",
    "            self._artifacts_consumed_cache = arts\n",
    "            self._deps_cache = ops\n",
    "        return self._inputs_cache\n",
    "\n",
    "    def inputs(self) -> Any:\n",
    "        \"\"\"\n",
    "        Get an operation's inputs\n",
    "        \"\"\"\n",
    "        return self._ensure_inputs()\n",
    "\n",
    "    def artifacts_consumed(self) -> Set[Artifact]:\n",
    "        \"\"\"\n",
    "        Get an operation's consumed artifacts\n",
    "        \"\"\"\n",
    "        if self._artifacts_consumed_cache is None:\n",
    "            self._ensure_inputs()\n",
    "        return self._artifacts_consumed_cache or set()\n",
    "\n",
    "    def deps(self) -> Set[Operation]:\n",
    "        \"\"\"\n",
    "        Get the dependencies of this operation\n",
    "        \"\"\"\n",
    "        if self._deps_cache is None:\n",
    "            self._ensure_inputs()\n",
    "        return self._deps_cache or set()\n",
    "\n",
    "    def used_by(self) -> Set[Operation]:\n",
    "        \"\"\"\n",
    "        Get the set of operations visible in the book used by this operation.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            Operation(self.book, op_id) \n",
    "            for op_id in self.book.fetch_artifact_consumed_by_many(self.artifacts_produced())\n",
    "        }\n",
    "\n",
    "    # --- JSON leaf builders for constructing inputs ---\n",
    "    def op_ref(self) -> Dict[str, Any]:\n",
    "        return {OP_TAG: {\"id\": self.id.hex(), \"path\": \"$\"}}\n",
    "    \n",
    "    def out(self, path: str) -> Dict[str, Any]:\n",
    "        return {OP_TAG: {\"id\": self.id.hex(), \"path\": path}}\n",
    "\n",
    "    # --- values via decoded cache ---\n",
    "    def value(self) -> Any:\n",
    "        return self.results()\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"\n",
    "        Validate that this operation is well-formed.\n",
    "\n",
    "        Currently checks that:\n",
    "        - The hash of this operation matches its ID\n",
    "        - No other operation's results are referenced in this operation's results\n",
    "        \"\"\"\n",
    "        inputs = self.inputs_json()\n",
    "        results = self.results_json()\n",
    "        assert self.header.op_id(inputs, results) == self.id, \\\n",
    "            f\"Operation ID mismatch for {self.id.hex()}\"\n",
    "        deps = set()\n",
    "        input_arts = set()\n",
    "        self.book.decode_json(inputs, ops=deps, arts=input_arts)\n",
    "        output_arts = set()\n",
    "        self.book.decode_json(results, arts=output_arts)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<Operation {self.id.hex()}>\"\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class OperationResult:\n",
    "    \"\"\"\n",
    "    Handle: (Operation, JSONPath) into that operation's decoded results.\n",
    "    Supports subscripting to extend the path: op[\"a\"][\"b\"][0]\n",
    "    \"\"\"\n",
    "    op: Operation\n",
    "    path: str\n",
    "\n",
    "    def __getitem__(self, key_or_index: Union[str, int]) -> \"OperationResult\":\n",
    "        \"\"\"Extend the JSONPath with a field or index.\"\"\"\n",
    "        return OperationResult(self.op, extend_path(self.path, key_or_index))\n",
    "\n",
    "    def value(self) -> Any:\n",
    "        \"\"\"\n",
    "        Evaluate JSONPath on the op's **decoded cached** results.\n",
    "        - 0 matches -> None\n",
    "        - 1 match   -> the value\n",
    "        - >1 matches-> list of values\n",
    "        \"\"\"\n",
    "        decoded = self.op._ensure_results()\n",
    "        expr = jsonpath_parse(self.path)\n",
    "        matches = [m.value for m in expr.find(decoded)]\n",
    "        if not matches:\n",
    "            return None\n",
    "        if len(matches) == 1:\n",
    "            return matches[0]\n",
    "        return matches\n",
    "\n",
    "    # JSON leaf for niceness (like op.op_ref/out)\n",
    "    def op_ref(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return the JSON leaf representation of this result reference.\"\"\"\n",
    "        return {OP_TAG: {\"id\": self.op.id.hex(), \"path\": self.path}}\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<OperationResult id={self.op.id.hex()} path={self.path!r}>\"\n",
    "\n",
    "\n",
    "# -------- Recorder (fixed config) --------\n",
    "class Recorder:\n",
    "    \"\"\"\n",
    "    Fixed (kind, task, tool, output_type).\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = (\"book\", \"kind\", \"task\", \"tool\", \"output_type\")\n",
    "\n",
    "    def __init__(self, book: \"Scrapebook\", *, kind: str, task: str, tool: str, output_type: str):\n",
    "        self.book = book\n",
    "        self.kind = kind\n",
    "        self.task = task\n",
    "        self.tool = tool\n",
    "        self.output_type = output_type\n",
    "\n",
    "    def record(self, inputs: Any, results: Any, meta: Any = None) -> Operation:\n",
    "        deps: Set[bytes] = set()\n",
    "        input_arts: Set[bytes] = set()\n",
    "        output_arts: Set[bytes] = set()\n",
    "        # allow op refs; collect deps\n",
    "        enc_inputs  = self._encode(inputs, ops=deps, arts=input_arts) \n",
    "        # forbid op refs in results \n",
    "        enc_results = self._encode(results, ops=None, arts=output_arts)\n",
    "          \n",
    "        # generate a UUID and timestamp if this is an observation\n",
    "        if self.kind == OBS_KIND:\n",
    "            event_uuid = os.urandom(32)\n",
    "            timestamp = datetime.now().isoformat()\n",
    "        else:\n",
    "            event_uuid = None\n",
    "            timestamp = None\n",
    "\n",
    "        header = OperationHeader(\n",
    "            kind=self.kind,\n",
    "            task=self.task,\n",
    "            tool=self.tool,\n",
    "            output_type=self.output_type,\n",
    "            event_uuid=event_uuid,\n",
    "            timestamp=timestamp,\n",
    "            meta=meta\n",
    "        )\n",
    "\n",
    "        op_id = self.book.persist_operation(\n",
    "            header=header,\n",
    "            inputs_json=enc_inputs,\n",
    "            results_json=enc_results,\n",
    "            deps=deps,\n",
    "            input_arts=input_arts,\n",
    "            output_arts=output_arts,\n",
    "        )\n",
    "        return Operation(self.book, op_id)\n",
    "\n",
    "    def _encode(self, obj: Any, *, \n",
    "        ops: Optional[Set[bytes]], arts: Optional[Set[bytes]]\n",
    "    ) -> Any:\n",
    "        # op refs\n",
    "        if isinstance(obj, OperationResult):\n",
    "            if ops is None:\n",
    "                raise ValueError(\"Operation references are not allowed here (ops=None).\")\n",
    "            ops.add(obj.op.id)\n",
    "            return obj.op_ref()\n",
    "        if isinstance(obj, Operation):\n",
    "            if ops is None:\n",
    "                raise ValueError(\"Operation references are not allowed here (ops=None).\")\n",
    "            ops.add(obj.id)\n",
    "            return obj.op_ref()\n",
    "        # artifacts\n",
    "        if isinstance(obj, Artifact):\n",
    "            if arts is None:\n",
    "                raise ValueError(\"Artifact references are not allowed here (arts=None).\")\n",
    "            arts.add(obj.sha256)\n",
    "            return {ART_TAG: obj.sha256.hex()}\n",
    "        if isinstance(obj, (bytes, bytearray, memoryview)):\n",
    "            sha256 = self.book.put_artifact_sha256(bytes(obj))  # -> \"<hex>\"\n",
    "            if arts is None:\n",
    "                raise ValueError(\"Artifact references are not allowed here (arts=None).\")\n",
    "            arts.add(sha256)\n",
    "            return {ART_TAG: sha256.hex()}\n",
    "\n",
    "        # containers / primitives\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: self._encode(v, ops=ops, arts=arts) for k, v in obj.items()}\n",
    "        if isinstance(obj, (list, tuple)):\n",
    "            return [self._encode(v, ops=ops, arts=arts) for v in obj]\n",
    "        return obj\n",
    "\n",
    "class Scrapebook(ABC):\n",
    "    \"\"\"\n",
    "    An ABC exposing the basic API for Scrapebook\n",
    "    \"\"\"\n",
    "    def recorder(self, *, kind: str, task: str, tool: str, output_type: str) -> Recorder:\n",
    "        return Recorder(self, kind=kind, task=task, tool=tool, output_type=output_type)\n",
    "\n",
    "    def obs_recorder(self, *, task: str, tool: str, output_type: str) -> Recorder:\n",
    "        return self.recorder(kind=OBS_KIND, task=task, tool=tool, output_type=output_type)\n",
    "\n",
    "    def trans_recorder(self, *, task: str, tool: str, output_type: str) -> Recorder:\n",
    "        return self.recorder(kind=TRANS_KIND, task=task, tool=tool, output_type=output_type)\n",
    "\n",
    "    @abstractmethod\n",
    "    def persist_operation(\n",
    "        self,\n",
    "        *,\n",
    "        header: OperationHeader,\n",
    "        inputs_json: Any,\n",
    "        results_json: Any,\n",
    "        deps: Set[bytes],\n",
    "        input_arts: Set[bytes],\n",
    "        output_arts: Set[bytes],\n",
    "    ) -> bytes:\n",
    "        \"\"\"\n",
    "        Persist an operation into the database\n",
    "\n",
    "        Returns its ID, which is a deterministic SHA-256 hash of the operation's contents.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def fetch_operation_header(self, op_id: bytes) -> OperationHeader:\n",
    "        \"\"\"\n",
    "        Fetch an operation header by its ID.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def fetch_results_json(self, op_id: bytes) -> Any:\n",
    "        \"\"\"\n",
    "        Fetch the raw JSON of an operation's results by its ID\n",
    "        \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fetch_inputs_json(self, op_id: bytes) -> Any:\n",
    "        \"\"\"\n",
    "        Fetch the raw JSON of an operation's inputs by its ID\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def put_artifact_sha256(self, data: bytes) -> bytes:\n",
    "        \"\"\"\n",
    "        Store bytes content-addressed by SHA-256 and return the hash as bytes.\n",
    "        \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fetch_artifact_bytes_sha256(self, sha256: bytes) -> bytes:\n",
    "        \"\"\"\n",
    "        Given the hash of a string of bytes, return the original bytes if known.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def fetch_artifact_produced_by(self, sha256: bytes) -> Iterable[bytes]:\n",
    "        \"\"\"\n",
    "        Given the hash of an artifact, return the set of operation IDs that produce it.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def fetch_artifact_consumed_by(self, sha256: bytes) -> Iterable[bytes]:\n",
    "        \"\"\"\n",
    "        Given the hash of an artifact, return the set of operation IDs that consume it.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def fetch_op_ids(self) -> Iterable[bytes]:\n",
    "        \"\"\"\n",
    "        Get an iterator over all operation IDs in the book.\n",
    "        \"\"\"\n",
    "\n",
    "    def decode_json(\n",
    "            self, node: Any, *, ops: Set[Operation] = None, arts: Set[Artifact] = None\n",
    "        ) -> Any:\n",
    "        \"\"\"\n",
    "        Decode JSON leaves back to handles, collecting dependencies along the way.\n",
    "\n",
    "        - Ops decode to lazy OperationResult and their IDs are collected\n",
    "          If `ops` is None, operation references are forbidden and will raise ValueError.\n",
    "        - Artifacts decode to lazy Artifact and their hashes are collected\n",
    "          If `arts` is None, artifact references are forbidden and will raise ValueError.\n",
    "\n",
    "        Returns: decoded_tree\n",
    "        \"\"\"\n",
    "        if isinstance(node, dict):\n",
    "            if OP_TAG in node:\n",
    "                if ops is None:\n",
    "                    raise ValueError(\"Operation references are not allowed here (ops=None).\")\n",
    "                try:\n",
    "                    spec = node[OP_TAG]\n",
    "                    op = Operation(self, hex_to_bytes(spec[\"id\"]))\n",
    "                    path = spec.get(\"path\", \"$\")\n",
    "                except:\n",
    "                    raise ValueError(f\"Invalid operation reference: {node!r}\")\n",
    "                ops.add(op)\n",
    "                return OperationResult(op, path)\n",
    "            if ART_TAG in node:\n",
    "                if arts is None:\n",
    "                    raise ValueError(\"Artifact references are not allowed here (arts=None).\")\n",
    "                try:\n",
    "                    sha = hex_to_bytes(node[ART_TAG])\n",
    "                except:\n",
    "                    raise ValueError(f\"Invalid artifact reference: {node!r}\") \n",
    "                art = Artifact(self, sha)\n",
    "                arts.add(art)\n",
    "                return art\n",
    "            return {k: self.decode_json(v, ops=ops, arts=arts) for k, v in node.items()}\n",
    "        if isinstance(node, list):\n",
    "            return [self.decode_json(v, ops=ops, arts=arts) for v in node]\n",
    "        return node\n",
    "    \n",
    "    def validate(self) -> int:\n",
    "        \"\"\"Validate this ScrapebookDict for internal consistency.\"\"\"\n",
    "        validated = 0\n",
    "        for op in self.fetch_op_ids():\n",
    "            Operation(self, op).validate()\n",
    "            validated += 1\n",
    "        return validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/imbrem/scrapebook/blob/main/scrapebook/core.py#L298){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### OperationResult.value\n",
       "\n",
       ">      OperationResult.value ()\n",
       "\n",
       "*Evaluate JSONPath on the op's **decoded cached** results.\n",
       "- 0 matches -> None\n",
       "- 1 match   -> the value\n",
       "- >1 matches-> list of values*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/imbrem/scrapebook/blob/main/scrapebook/core.py#L298){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### OperationResult.value\n",
       "\n",
       ">      OperationResult.value ()\n",
       "\n",
       "*Evaluate JSONPath on the op's **decoded cached** results.\n",
       "- 0 matches -> None\n",
       "- 1 match   -> the value\n",
       "- >1 matches-> list of values*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(OperationResult.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/imbrem/scrapebook/blob/main/scrapebook/core.py#L239){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Operation.inputs\n",
       "\n",
       ">      Operation.inputs ()\n",
       "\n",
       "*Get an operation's inputs*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/imbrem/scrapebook/blob/main/scrapebook/core.py#L239){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Operation.inputs\n",
       "\n",
       ">      Operation.inputs ()\n",
       "\n",
       "*Get an operation's inputs*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Operation.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/imbrem/scrapebook/blob/main/scrapebook/core.py#L205){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Operation.results\n",
       "\n",
       ">      Operation.results ()\n",
       "\n",
       "*Get the results of an operation*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/imbrem/scrapebook/blob/main/scrapebook/core.py#L205){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Operation.results\n",
       "\n",
       ">      Operation.results ()\n",
       "\n",
       "*Get the results of an operation*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Operation.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapebookDict(Scrapebook):\n",
    "    def __init__(self):\n",
    "        self.ops = dict()\n",
    "        self.arts = dict()\n",
    "        self.deps = dict()\n",
    "        self.op_used_by = dict()\n",
    "        self.produced_by = dict()\n",
    "        self.consumed_by = dict()\n",
    "        pass\n",
    "\n",
    "    # persistence\n",
    "    def persist_operation(\n",
    "        self,\n",
    "        *,\n",
    "        header: OperationHeader,\n",
    "        inputs_json: Any,\n",
    "        results_json: Any,\n",
    "        deps: Set[bytes],\n",
    "        input_arts: Set[bytes],\n",
    "        output_arts: Set[bytes]\n",
    "    ) -> bytes:\n",
    "        op_id = header.op_id(inputs_json, results_json)\n",
    "        self.ops[op_id] = { \"header\" : header, \"input\" : inputs_json, \"result\" : results_json}\n",
    "        for dep in deps:\n",
    "            self.op_used_by.setdefault(dep, set()).add(op_id)\n",
    "            self.deps.setdefault(op_id, set()).add(dep)\n",
    "        for art in input_arts:\n",
    "            self.consumed_by.setdefault(art, set()).add(op_id)\n",
    "        for art in output_arts:\n",
    "            self.produced_by.setdefault(art, set()).add(op_id)\n",
    "        return op_id\n",
    "\n",
    "    def fetch_operation_header(self, op_id: bytes) -> OperationHeader:\n",
    "        return self.ops[op_id][\"header\"]\n",
    "\n",
    "    def fetch_results_json(self, op_id: bytes) -> Any:\n",
    "        return self.ops[op_id][\"result\"]\n",
    "    \n",
    "    def fetch_inputs_json(self, op_id: bytes) -> Any:\n",
    "        return self.ops[op_id][\"input\"]\n",
    "\n",
    "    def fetch_op_ids(self) -> Iterable[bytes]:\n",
    "        return self.ops.keys()\n",
    "\n",
    "    def put_artifact_sha256(self, data: bytes) -> bytes:\n",
    "        \"\"\"Store bytes content-addressed by SHA-256 and return the hex hash.\"\"\"\n",
    "        hash = hashlib.sha256(data).digest()\n",
    "        self.arts[hash] = data\n",
    "        return hash\n",
    "    \n",
    "    def fetch_artifact_bytes_sha256(self, sha256: bytes) -> bytes:\n",
    "        return self.arts[sha256]\n",
    "    \n",
    "    def fetch_artifact_produced_by(self, sha256: bytes) -> Iterable[bytes]:\n",
    "        \"\"\"\n",
    "        Given the hash of an artifact, return the set of operation IDs that produce it.\n",
    "        \"\"\"\n",
    "        return self.produced_by.get(sha256, set())\n",
    "\n",
    "    def fetch_artifact_consumed_by(self, sha256: bytes) -> Iterable[bytes]:\n",
    "        \"\"\"\n",
    "        Given the hash of an artifact, return the set of operation IDs that consume it.\n",
    "        \"\"\"\n",
    "        return self.consumed_by.get(sha256, set())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = ScrapebookDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapes = book.obs_recorder(task=\"scrape_site\", tool=\"demo\", output_type=\"http_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = scrapes.record({\"url\": \"http://example.com\"}, {\"status\": 200, \"content\": b\"hello\"})\n",
    "op.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.fetch_artifact_produced_by(op.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Operation ae67f785a7e39b117161a13fdd2d6a5139f3e42d8bea6f9e3b264e853a45d784>,\n",
       " 'obs',\n",
       " 'scrape_site',\n",
       " 'demo',\n",
       " 'http_response',\n",
       " '0321dd21d2eabb8da0ea55383fabc053e4bccf7dc2f87c1de29404f0eee5b466',\n",
       " '2025-10-05T02:58:41.209504',\n",
       " None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(op, op.kind, op.task, op.tool, op.output_type, op.event_uuid.hex(), op.timestamp, op.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 200,\n",
       " 'content': {'$artifact': '2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.results_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 200,\n",
       " 'content': <Artifact 2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[\"content\"].value().bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OperationResult id=ae67f785a7e39b117161a13fdd2d6a5139f3e42d8bea6f9e3b264e853a45d784 path='$[\"content\"]'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = book.trans_recorder(task=\"parse_article\", tool=\"demo2\", output_type=\"article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2 = articles.record({\"content\" : op[\"content\"], \"mode\": \"cool\"}, \"good article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Operation d37127eba9c227c45f73d26c34d4305f90ceff4a0f253577e809a32bbc243cc8>,\n",
       " 'trans',\n",
       " 'parse_article',\n",
       " 'demo2',\n",
       " 'article',\n",
       " None,\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    op2, op2.kind, op2.task, op2.tool, op2.output_type, op2.event_uuid, \n",
    "    op2.timestamp, op2.meta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good article'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': <OperationResult id=ae67f785a7e39b117161a13fdd2d6a5139f3e42d8bea6f9e3b264e853a45d784 path='$[\"content\"]'>,\n",
       " 'mode': 'cool'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2.inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Operation ae67f785a7e39b117161a13fdd2d6a5139f3e42d8bea6f9e3b264e853a45d784>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dep for dep in op2.deps()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op3 = articles.record(\n",
    "    {\"content\" : op[\"content\"], \"mode\": op2, \"status\": op[\"status\"]}, \n",
    "    \"better article\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Operation f60c4785522a91181c5110336408465d2591b9f34a59b231ec2e5deea6b48377>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better article'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op3.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Operation ae67f785a7e39b117161a13fdd2d6a5139f3e42d8bea6f9e3b264e853a45d784>,\n",
       " <Operation d37127eba9c227c45f73d26c34d4305f90ceff4a0f253577e809a32bbc243cc8>,\n",
       " <Operation ae67f785a7e39b117161a13fdd2d6a5139f3e42d8bea6f9e3b264e853a45d784>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dep for dep in op3.deps()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Operation ae67f785a7e39b117161a13fdd2d6a5139f3e42d8bea6f9e3b264e853a45d784>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Artifact 2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.artifacts_produced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
