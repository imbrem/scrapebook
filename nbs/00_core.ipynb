{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, Optional, Iterable, Set, Union, Tuple\n",
    "import hashlib\n",
    "from jsonpath_ng import parse as jsonpath_parse\n",
    "import json\n",
    "import re\n",
    "\n",
    "_HEX_RE = re.compile(r'^[0-9a-fA-F]*$')\n",
    "\n",
    "def hex_to_bytes(h: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Convert a hex string to raw bytes.\n",
    "\n",
    "    Accepts optional '0x' prefix and common separators (space, underscore,\n",
    "    hyphen, colon). Raises TypeError for non-str inputs and ValueError for\n",
    "    invalid hex or odd length after cleaning.\n",
    "    \"\"\"\n",
    "    if not isinstance(h, str):\n",
    "        raise TypeError(\"hex_to_bytes() expects a str\")\n",
    "\n",
    "    s = h.strip()\n",
    "    if s.startswith((\"0x\", \"0X\")):\n",
    "        s = s[2:]\n",
    "\n",
    "    # Remove common separators\n",
    "    for sep in (\" \", \"_\", \"-\", \":\"):\n",
    "        s = s.replace(sep, \"\")\n",
    "\n",
    "    if len(s) % 2 != 0:\n",
    "        raise ValueError(f\"hex string has odd length ({len(s)}): {h!r}\")\n",
    "\n",
    "    if not _HEX_RE.fullmatch(s):\n",
    "        raise ValueError(f\"invalid hex string: {h!r}\")\n",
    "\n",
    "    return bytes.fromhex(s)\n",
    "\n",
    "def sha256_hex(data: bytes) -> str:\n",
    "    \"\"\"Get the hex digest of the SHA-256 hash of the given data\"\"\"\n",
    "    return hashlib.sha256(data).hexdigest()\n",
    "\n",
    "def path_for_key(key: str) -> str:\n",
    "    \"\"\"Get a JSONPath for a given key using bracket notation.\"\"\"\n",
    "    safe = key.replace('\"', r'\\\"')\n",
    "    return f'$[\"{safe}\"]'\n",
    "\n",
    "def extend_path(base: str, key_or_index: Union[str, int]) -> str:\n",
    "    \"\"\"Append a segment to a JSONPath using bracket notation.\"\"\"\n",
    "    if isinstance(key_or_index, str):\n",
    "        seg = path_for_key(key_or_index)[1:]  # '[\"key\"]'\n",
    "        return f\"{base}{seg}\"\n",
    "    if isinstance(key_or_index, int):\n",
    "        return f\"{base}[{key_or_index}]\"\n",
    "    raise TypeError(\"Path extension must be str (field) or int (index).\")\n",
    "\n",
    "def hash_json(data: Any) -> bytes:\n",
    "    \"\"\"Compute a SHA-256 hash of JSON-serializable data.\"\"\"\n",
    "    j = json.dumps(data, separators=(',', ':'), sort_keys=True)\n",
    "    return hashlib.sha256(j.encode('utf-8')).digest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class OperationHeader:\n",
    "    \"\"\"Metadata about an operation.\"\"\"\n",
    "    kind: str # e.g. 'observe' or 'transform' \n",
    "    task: str # e.g. 'fetch_http', 'parse_article'\n",
    "    tool: str # e.g. 'requests', 'my_scraper_1'\n",
    "    output_type: str # e.g. 'http_response', 'article'\n",
    "    event_uuid: Optional[str] # e.g. '550e8400-e29b-41d4-a716-446655440000'\n",
    "    timestamp: Optional[str] # e.g. '2024-01-01T12:00:00Z'\n",
    "\n",
    "    def sha256(self) -> bytes:\n",
    "        \"\"\"\n",
    "        Deterministic SHA-256 over all fields as plain data.\n",
    "        Uses a canonical JSON *list* to preserve field order.\n",
    "        \"\"\"\n",
    "        return hash_json([\n",
    "            self.kind, self.task, self.tool, self.output_type, self.event_uuid, \n",
    "            self.timestamp\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# -------- JSON leaf tags --------\n",
    "OP_TAG  = \"$op\"          # {\"$op\": {\"id\": \"<hex>\", \"path\": \"$.a.b[0]\"}}\n",
    "ART_TAG = \"$artifact\"    # {\"$artifact\": \"<sha256-hex>\"}\n",
    "\n",
    "class Artifact:\n",
    "    \"\"\"Lazy-loaded bytes referenced by SHA-256; caches after first load.\"\"\"\n",
    "    __slots__ = (\"book\", \"sha256\", \"_cache\")\n",
    "    def __init__(self, book: \"Scrapebook\", sha256: bytes):\n",
    "        self.book = book\n",
    "        self.sha256 = sha256\n",
    "        self._cache: Optional[bytes] = None\n",
    "    def bytes(self) -> bytes:\n",
    "        if self._cache is None:\n",
    "            self._cache = self.book._fetch_artifact_bytes_sha256(self.sha256)\n",
    "        return self._cache\n",
    "    def value(self) -> bytes:\n",
    "        return self.bytes()\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<Artifact {self.sha256.hex()}>\"\n",
    "\n",
    "\n",
    "class Operation:\n",
    "    \"\"\"Lazy header; decoded results/inputs are cached along with their dependency sets.\"\"\"\n",
    "    __slots__ = (\n",
    "        \"book\", \"id\", \"_header\",\n",
    "        \"_results_decoded_cache\",\n",
    "        \"_result_artifact_deps_cache\",\n",
    "        \"_inputs_decoded_cache\",\n",
    "        \"_input_artifact_deps_cache\", \"_input_op_deps_cache\",\n",
    "    )\n",
    "    def __init__(self, book: \"Scrapebook\", op_id: bytes):\n",
    "        self.book = book\n",
    "        self.id = op_id\n",
    "        self._header: Optional[OperationHeader] = None\n",
    "\n",
    "        # Results caches\n",
    "        self._results_decoded_cache: Optional[Any] = None\n",
    "        self._result_artifact_deps_cache: Optional[Set[str]] = None\n",
    "\n",
    "        # Inputs caches\n",
    "        self._inputs_decoded_cache: Optional[Any] = None\n",
    "        self._input_artifact_deps_cache: Optional[Set[str]] = None\n",
    "        self._input_op_deps_cache: Optional[Set[bytes]] = None\n",
    "\n",
    "    # --- header (lazy) ---\n",
    "    @property\n",
    "    def header(self) -> OperationHeader:\n",
    "        if self._header is None:\n",
    "            self._header = self.book._fetch_operation_header(self.id)\n",
    "        return self._header\n",
    "\n",
    "    @property\n",
    "    def kind(self) -> str: return self.header.kind\n",
    "    @property\n",
    "    def task(self) -> str: return self.header.task\n",
    "    @property\n",
    "    def tool(self) -> str: return self.header.tool\n",
    "    @property\n",
    "    def output_type(self) -> str: return self.header.output_type\n",
    "    @property\n",
    "    def event_uuid(self) -> Optional[str]: return self.header.event_uuid\n",
    "    @property\n",
    "    def timestamp(self) -> Optional[str]: return self.header.timestamp\n",
    "\n",
    "    # --- result-path handles ---\n",
    "    def __getitem__(self, key: str) -> \"OperationResult\":\n",
    "        return self.at(path_for_key(key))\n",
    "    def at(self, path: str) -> \"OperationResult\":\n",
    "        return OperationResult(self, path)\n",
    "\n",
    "    # --- results JSON (raw / decoded + deps) ---\n",
    "    def results_json(self) -> Any:\n",
    "        return self.book._fetch_results_json(self.id)\n",
    "\n",
    "    def _ensure_results_decoded(self) -> Any:\n",
    "        if self._results_decoded_cache is None:\n",
    "            raw = self.book._fetch_results_json(self.id)\n",
    "            arts = set()\n",
    "            decoded = self.book.decode_json(raw, arts=arts)\n",
    "            self._results_decoded_cache = decoded\n",
    "            self._result_artifact_deps_cache = arts\n",
    "        return self._results_decoded_cache\n",
    "\n",
    "    def results_decoded(self) -> Any:\n",
    "        return self._ensure_results_decoded()\n",
    "\n",
    "    def result_artifact_deps(self) -> Set[str]:\n",
    "        if self._result_artifact_deps_cache is None:\n",
    "            self._ensure_results_decoded()\n",
    "        return self._result_artifact_deps_cache or set()\n",
    "\n",
    "    # --- inputs JSON (raw / decoded + deps) ---\n",
    "    def inputs_json(self) -> Any:\n",
    "        return self.book._fetch_inputs_json(self.id)\n",
    "\n",
    "    def _ensure_inputs_decoded(self) -> Any:\n",
    "        if self._inputs_decoded_cache is None:\n",
    "            raw = self.book._fetch_inputs_json(self.id)\n",
    "            arts = set()\n",
    "            ops = set()\n",
    "            decoded = self.book.decode_json(raw, ops=ops, arts=arts)\n",
    "            self._inputs_decoded_cache = decoded\n",
    "            self._input_artifact_deps_cache = arts\n",
    "            self._input_op_deps_cache = ops\n",
    "        return self._inputs_decoded_cache\n",
    "\n",
    "    def inputs_decoded(self) -> Any:\n",
    "        return self._ensure_inputs_decoded()\n",
    "\n",
    "    def input_artifact_deps(self) -> Set[str]:\n",
    "        if self._input_artifact_deps_cache is None:\n",
    "            self._ensure_inputs_decoded()\n",
    "        return self._input_artifact_deps_cache or set()\n",
    "\n",
    "    def input_op_deps(self) -> Set[bytes]:\n",
    "        if self._input_op_deps_cache is None:\n",
    "            self._ensure_inputs_decoded()\n",
    "        return self._input_op_deps_cache or set()\n",
    "\n",
    "    # --- JSON leaf builders for constructing inputs ---\n",
    "    def op_ref(self) -> Dict[str, Any]:\n",
    "        return {OP_TAG: {\"id\": self.id.hex(), \"path\": \"$\"}}\n",
    "    \n",
    "    def out(self, path: str) -> Dict[str, Any]:\n",
    "        return {OP_TAG: {\"id\": self.id.hex(), \"path\": path}}\n",
    "\n",
    "    # --- values via decoded cache ---\n",
    "    def value(self) -> Any:\n",
    "        return self.results_decoded()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<Operation {self.id.hex()}>\"\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class OperationResult:\n",
    "    \"\"\"\n",
    "    Handle: (Operation, JSONPath) into that operation's decoded results.\n",
    "    Supports subscripting to extend the path: op[\"a\"][\"b\"][0]\n",
    "    \"\"\"\n",
    "    op: Operation\n",
    "    path: str\n",
    "\n",
    "    def __getitem__(self, key_or_index: Union[str, int]) -> \"OperationResult\":\n",
    "        \"\"\"Extend the JSONPath with a field or index.\"\"\"\n",
    "        return OperationResult(self.op, extend_path(self.path, key_or_index))\n",
    "\n",
    "    def value(self) -> Any:\n",
    "        \"\"\"\n",
    "        Evaluate JSONPath on the op's **decoded cached** results.\n",
    "        - 0 matches -> None\n",
    "        - 1 match   -> the value\n",
    "        - >1 matches-> list of values\n",
    "        \"\"\"\n",
    "        decoded = self.op._ensure_results_decoded()\n",
    "        expr = jsonpath_parse(self.path)\n",
    "        matches = [m.value for m in expr.find(decoded)]\n",
    "        if not matches:\n",
    "            return None\n",
    "        if len(matches) == 1:\n",
    "            return matches[0]\n",
    "        return matches\n",
    "\n",
    "    # JSON leaf for niceness (like op.op_ref/out)\n",
    "    def op_ref(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return the JSON leaf representation of this result reference.\"\"\"\n",
    "        return {OP_TAG: {\"id\": self.op.id.hex(), \"path\": self.path}}\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<OperationResult id={self.op.id.hex()} path={self.path!r}>\"\n",
    "\n",
    "\n",
    "# -------- Recorder (fixed config) --------\n",
    "class Recorder:\n",
    "    \"\"\"\n",
    "    Fixed (kind, task, tool, output_type).\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = (\"book\", \"kind\", \"task\", \"tool\", \"output_type\")\n",
    "\n",
    "    def __init__(self, book: \"Scrapebook\", *, kind: str, task: str, tool: str, output_type: str):\n",
    "        self.book = book\n",
    "        self.kind = kind\n",
    "        self.task = task\n",
    "        self.tool = tool\n",
    "        self.output_type = output_type\n",
    "\n",
    "    def record(self, inputs: Any, results: Any) -> Operation:\n",
    "        op_deps: Set[bytes] = set()\n",
    "        input_arts: Set[bytes] = set()\n",
    "        output_arts: Set[bytes] = set()\n",
    "        # allow op refs; collect deps\n",
    "        enc_inputs  = self._encode(inputs, ops=op_deps, arts=input_arts) \n",
    "        # forbid op refs in results \n",
    "        enc_results = self._encode(results, ops=None, arts=output_arts)    \n",
    "        op_id = self.book._persist_operation(\n",
    "            kind=self.kind,\n",
    "            task=self.task,\n",
    "            tool=self.tool,\n",
    "            output_type=self.output_type,\n",
    "            inputs_json=enc_inputs,\n",
    "            results_json=enc_results,\n",
    "            op_deps=op_deps,\n",
    "            input_arts=input_arts,\n",
    "            output_arts=output_arts,\n",
    "            event_uuid=None,\n",
    "            timestamp=None,\n",
    "        )\n",
    "        return Operation(self.book, op_id)\n",
    "\n",
    "    def _encode(self, obj: Any, *, \n",
    "        ops: Optional[Set[bytes]], arts: Optional[Set[bytes]]\n",
    "    ) -> Any:\n",
    "        # op refs\n",
    "        if isinstance(obj, OperationResult):\n",
    "            if ops is None:\n",
    "                raise ValueError(\"Operation references are not allowed here (ops=None).\")\n",
    "            ops.add(obj.op.id)\n",
    "            return obj.op_ref()\n",
    "        if isinstance(obj, Operation):\n",
    "            if ops is None:\n",
    "                raise ValueError(\"Operation references are not allowed here (ops=None).\")\n",
    "            ops.add(obj.id)\n",
    "            return obj.op_ref()\n",
    "        # artifacts\n",
    "        if isinstance(obj, Artifact):\n",
    "            if arts is None:\n",
    "                raise ValueError(\"Artifact references are not allowed here (arts=None).\")\n",
    "            arts.add(obj.sha256)\n",
    "            return {ART_TAG: obj.sha256.hex()}\n",
    "        if isinstance(obj, (bytes, bytearray, memoryview)):\n",
    "            h = self.book._put_artifact_sha256(bytes(obj)).hex()  # -> \"<hex>\"\n",
    "            return {ART_TAG: h}\n",
    "\n",
    "        # containers / primitives\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: self._encode(v, ops=ops, arts=arts) for k, v in obj.items()}\n",
    "        if isinstance(obj, (list, tuple)):\n",
    "            return [self._encode(v, ops=ops, arts=arts) for v in obj]\n",
    "        return obj\n",
    "\n",
    "\n",
    "# -------- Scrapebook (DB façade; stubs + ALWAYS-collect decoder) --------\n",
    "class Scrapebook:\n",
    "    def __init__(self):\n",
    "        # map operation ids to headers + inputs + outputs\n",
    "        self.ops = dict()\n",
    "        self.arts = dict()\n",
    "        pass\n",
    "\n",
    "    def recorder(self, *, kind: str, task: str, tool: str, output_type: str) -> Recorder:\n",
    "        return Recorder(self, kind=kind, task=task, tool=tool, output_type=output_type)\n",
    "\n",
    "    def obs_recorder(self, *, task: str, tool: str, output_type: str) -> Recorder:\n",
    "        return self.recorder(kind=\"observe\", task=task, tool=tool, output_type=output_type)\n",
    "\n",
    "    def trans_recorder(self, *, task: str, tool: str, output_type: str) -> Recorder:\n",
    "        return self.recorder(kind=\"transform\", task=task, tool=tool, output_type=output_type)\n",
    "\n",
    "    # persistence\n",
    "    def _persist_operation(\n",
    "        self,\n",
    "        *,\n",
    "        kind: str,\n",
    "        task: str,\n",
    "        tool: str,\n",
    "        output_type: str,\n",
    "        inputs_json: Any,\n",
    "        results_json: Any,\n",
    "        op_deps: Set[bytes],\n",
    "        input_arts: Set[bytes],\n",
    "        output_arts: Set[bytes],\n",
    "        event_uuid: Optional[str],\n",
    "        timestamp: Optional[str],\n",
    "    ) -> bytes:\n",
    "        #TODO: store op deps\n",
    "        header = OperationHeader(kind, task, tool, output_type, event_uuid, timestamp)\n",
    "        op_id = hash_json([header.sha256().hex(), inputs_json, results_json])\n",
    "        self.ops[op_id] = { \"header\" : header, \"input\" : inputs_json, \"result\" : results_json}\n",
    "        return op_id\n",
    "\n",
    "    # header\n",
    "    def _fetch_operation_header(self, op_id: bytes) -> OperationHeader:\n",
    "        return self.ops[op_id][\"header\"]\n",
    "\n",
    "    # JSON fetch\n",
    "    def _fetch_results_json(self, op_id: bytes) -> Any:\n",
    "        return self.ops[op_id][\"result\"]\n",
    "    \n",
    "    def _fetch_inputs_json(self, op_id: bytes) -> Any:\n",
    "        return self.ops[op_id][\"input\"]\n",
    "\n",
    "    # artifacts (fixed SHA-256)\n",
    "    def _put_artifact_sha256(self, data: bytes) -> bytes:\n",
    "        \"\"\"Store bytes content-addressed by SHA-256 and return the hex hash.\"\"\"\n",
    "        hash = hashlib.sha256(data).digest()\n",
    "        self.arts[hash] = data\n",
    "        return hash\n",
    "    \n",
    "    def _fetch_artifact_bytes_sha256(self, sha256: bytes) -> bytes:\n",
    "        return self.arts[sha256]\n",
    "\n",
    "    def decode_json(\n",
    "            self, node: Any, *, ops: Set[bytes] = None, arts: Set[bytes] = None) -> Any:\n",
    "        \"\"\"\n",
    "        Decode JSON leaves back to handles, collecting dependencies along the way.\n",
    "\n",
    "        - Ops decode to lazy OperationResult and their IDs are collected\n",
    "          If `ops` is None, operation references are forbidden and will raise ValueError.\n",
    "        - Artifacts decode to lazy Artifact and their hashes are collected\n",
    "          If `arts` is None, artifact references are forbidden and will raise ValueError.\n",
    "\n",
    "        Returns: decoded_tree\n",
    "        \"\"\"\n",
    "        if isinstance(node, dict):\n",
    "            if OP_TAG in node:\n",
    "                if ops is None:\n",
    "                    raise ValueError(\"Operation references are not allowed here (ops=None).\")\n",
    "                try:\n",
    "                    spec = node[OP_TAG]\n",
    "                    op = Operation(self, hex_to_bytes(spec[\"id\"]))\n",
    "                    path = spec.get(\"path\", \"$\")\n",
    "                except:\n",
    "                    raise ValueError(f\"Invalid operation reference: {node!r}\")\n",
    "                ops.add(op.id)\n",
    "                return OperationResult(op, path)\n",
    "            if ART_TAG in node:\n",
    "                if arts is None:\n",
    "                    raise ValueError(\"Artifact references are not allowed here (arts=None).\")\n",
    "                try:\n",
    "                    sha = hex_to_bytes(node[ART_TAG])\n",
    "                except:\n",
    "                    raise ValueError(f\"Invalid artifact reference: {node!r}\") \n",
    "                arts.add(sha)\n",
    "                return Artifact(self, sha)\n",
    "            return {k: self.decode_json(v, ops=ops, arts=arts) for k, v in node.items()}\n",
    "        if isinstance(node, list):\n",
    "            return [self.decode_json(v, ops=ops, arts=arts) for v in node]\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = Scrapebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapes = book.obs_recorder(task=\"scrape_site\", tool=\"demo\", output_type=\"http_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = scrapes.record({\"url\": \"http://example.com\"}, {\"status\": 200, \"content\": b\"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Operation 0cea232512a0908ab4eb409dccfe03f566ee9f36f2c6dda01ab97910cd21ed5b>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('observe', 'scrape_site', 'demo', 'http_response')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(op.kind, op.task, op.tool, op.output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 200,\n",
       " 'content': {'$artifact': '2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.results_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 200,\n",
       " 'content': <Artifact 2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.results_decoded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[\"content\"].value().bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OperationResult id=0cea232512a0908ab4eb409dccfe03f566ee9f36f2c6dda01ab97910cd21ed5b path='$[\"content\"]'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = book.trans_recorder(task=\"parse_article\", tool=\"demo2\", output_type=\"article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2 = articles.record({\"content\" : op[\"content\"], \"mode\": \"cool\"}, \"good article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Operation 9251d9e6006363cedcb4bd14c98f80d4a4de22e5b0af763cf087ee75f73e14ca>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good article'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': <OperationResult id=0cea232512a0908ab4eb409dccfe03f566ee9f36f2c6dda01ab97910cd21ed5b path='$[\"content\"]'>,\n",
       " 'mode': 'cool'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2.inputs_decoded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0cea232512a0908ab4eb409dccfe03f566ee9f36f2c6dda01ab97910cd21ed5b']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dep.hex() for dep in op2.input_op_deps()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op3 = articles.record(\n",
    "    {\"content\" : op[\"content\"], \"mode\": op2, \"status\": op[\"status\"]}, \n",
    "    \"better article\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Operation fb667362593df912db68321709893d297fab97d78f3ba13ff795bc6fdf6abeba>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better article'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op3.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9251d9e6006363cedcb4bd14c98f80d4a4de22e5b0af763cf087ee75f73e14ca',\n",
       " '0cea232512a0908ab4eb409dccfe03f566ee9f36f2c6dda01ab97910cd21ed5b']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dep.hex() for dep in op3.input_op_deps()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Operation 0cea232512a0908ab4eb409dccfe03f566ee9f36f2c6dda01ab97910cd21ed5b>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Operation 9251d9e6006363cedcb4bd14c98f80d4a4de22e5b0af763cf087ee75f73e14ca>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
